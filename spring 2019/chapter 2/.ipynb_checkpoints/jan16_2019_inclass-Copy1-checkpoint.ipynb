{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**January 16 2019**  \n",
    "**ATMOS 5040: Environmental Statistics**  \n",
    "**John Horel **\n",
    "\n",
    "Download this notebook and all images and data by downloading the ZIP file from GitHub, or use the git command:\n",
    "\n",
    "    git clone https://github.com/johnhorel/ATMOS_5040_2019.git\n",
    "    \n",
    "> Note: Windows users will have to install [git for Windows](https://gitforwindows.org/) and execute the git command from the PowerShell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python modules\n",
    "\n",
    "`numpy` provides routines to handle arrays and many calculations efficiently and imported by convention as `np`. Numpy functions are very good at handling homogeneous data arrays (and similar in that respect to matlab functions).\n",
    "\n",
    "`pandas` is really good at handling tabular/array data that may have heterogeneous types (floating and text, for example). It is imported by convention as `pd`. \n",
    "\n",
    "There are a couple sets of panda library routines  (`Series`, and `DataFrame`) used so frequently that we'll import those directly too.\n",
    "\n",
    "`scipy` has a bunch of statistical functions and we'll import `stats` from `scipy`\n",
    "\n",
    "\n",
    "\n",
    "`pyplot` is a _submodule_ of matplotlib. It is typically imported as the alias `plt` to handle basic plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# January 16, 2019 Inclass assignment\n",
    "\n",
    "# Long-term variations in Alta snowfall\n",
    "\n",
    "For info on the data\n",
    "http://utahavalanchecenter.org/alta-monthly-snowfall\n",
    "\n",
    "On GitHub, look in the `data` folder for a file called `alta_snow.csv` and download it. \n",
    "\n",
    "Open the `alta_snow.csv` file in the Jupyter Lab environment to see the column contents and the units.\n",
    "\n",
    "-column 0 is the year and column 7 is the seasonal total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the lake level data\n",
    "year = np.genfromtxt('../data/alta_snow.csv', delimiter=',', usecols=0)\n",
    "#convert seasonal totals from inches to cm\n",
    "tot = 2.54 * np.genfromtxt('../data/alta_snow.csv', delimiter=',', usecols=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(year)\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some basic calcs on the Alta snowfall data\n",
    "\n",
    "%compute the means of each column\n",
    "mmn = mean(data);\n",
    "% determine max value and index value of max for the winter season\n",
    "[maxs,mxi] = max(tot);\n",
    "% write to screen the year when max occurred\n",
    "fprintf('year of max seasonal snowfall and amount %d %.1f cm\\n', yr(mxi),maxs)\n",
    "%repeat for min \n",
    "[mins,mni] = min(tot);\n",
    "fprintf('year of min seasonal snowfall and amount %d %.1f cm\\n', yr(mni),mins)\n",
    "\n",
    "%plot time series of snow totals as bar chart\n",
    "figure(1)\n",
    "bar(yr,tot)\n",
    "axis('tight')\n",
    "title('Alta water year snow total (cm) John Horel 12/30/2018')\n",
    "xlabel('Year')\n",
    "ylabel('Snow total (cm)')\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2.1\n",
    "\n",
    "Create bar plot time series of lake level, Utah ppt, and Utah temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = np.arange(1950,2020,5)\n",
    "\n",
    "fig,(ax1) = plt.subplots(1,1,figsize=(10,10))\n",
    "ax1.bar(year,tot,color='green')\n",
    "ax1.set(xlim=(1946,2018),ylim=(500,2000))\n",
    "ax1.set(xlabel=\"Year\",ylabel='Snow Total (cm)')\n",
    "ax1.set(xticks=decade_ticks)\n",
    "ax1.set(title=\"Alta water year snow total (cm) John Horel 1/13/2019\")\n",
    "ax1.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "\n",
    "plt.savefig('alta_anow_inclass_2019_python.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the values from smallest to largest using numpy\n",
    "levsort = np.sort(lev)\n",
    "print(levsort)\n",
    "#compute the range\n",
    "range_lev = np.max(lev) - np.min(lev)\n",
    "print('range',range_lev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this will seem odd but the matplotlib hist function doesn't work for noninteger intervals, \n",
    "#so using numpy version and then plotting\n",
    "fig2,ax = plt.subplots(2,2,figsize=(10,10))\n",
    "x1 = np.arange(1277,1285,1)\n",
    "hist_val1,bins1 = np.histogram(lev,x1)\n",
    "width1 = 0.6 * (bins1[1] - bins1[0])\n",
    "center1 = (bins1[:-1] + bins1[1:]) / 2\n",
    "ax1 = ax[0,0]\n",
    "ax1.bar(center1,hist_val1,align='center',width=width1,color='cyan')\n",
    "ax1.set(xlim=(1277,1284),ylim=(0,40))\n",
    "ax1.set(xlabel=\"Level(m)\",ylabel='Count')\n",
    "\n",
    "x2 = np.arange(1277.,1285.01,0.5)\n",
    "hist_val2,bins2 = np.histogram(lev,x2)\n",
    "width2 = 0.6 * (bins2[1] - bins2[0])\n",
    "center2 = (bins2[:-1] + bins2[1:]) / 2\n",
    "ax2 = ax[0,1]\n",
    "ax2.bar(center2,hist_val2,align='center',width=width2,color='cyan')\n",
    "ax2.set(xlim=(1277,1284),ylim=(0,25))\n",
    "ax2.set(xlabel=\"Level(m)\",ylabel='Count')\n",
    "\n",
    "#display probabilities\n",
    "#get total number of values\n",
    "N = len(lev)\n",
    "#need to weight each of the values so each one is a probability\n",
    "weights = np.ones_like(lev)/float(N)\n",
    "hist_val3,bins3 = np.histogram(lev,x1,weights=weights)\n",
    "ax3 = ax[1,0]\n",
    "ax3.bar(center1,hist_val3,align='center',width=width1,color='cyan')\n",
    "ax3.set(xlim=(1277,1284),ylim=(0,0.4))\n",
    "ax3.set(xlabel=\"Level(m)\",ylabel='Probability')\n",
    "\n",
    "hist_val4,bins4 = np.histogram(lev,x2,weights=weights)\n",
    "ax4 = ax[1,1]\n",
    "ax4.bar(center2,hist_val4,align='center',width=width2,color='cyan')\n",
    "ax4.set(xlim=(1277,1284),ylim=(0,0.2))\n",
    "ax4.set(xlabel=\"Level(m)\",ylabel='Probability')\n",
    "\n",
    "\n",
    "plt.savefig('figure_2.2_2019_python.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2.3\n",
    "\n",
    "Cumulative probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cumulative histogram\n",
    "fig3,ax = plt.subplots(1,1,figsize=(10,5))\n",
    "n_bins = 124\n",
    "n, bins, patches = ax.hist(lev, n_bins, density='True', histtype='step',\n",
    "                           cumulative=True, label='Empirical')\n",
    "ax.set(xlabel=\"Level(m)\",ylabel='Cumulative Emprical Probability')\n",
    "ax.set(xlim=(min(lev),max(lev)))\n",
    "\n",
    "\n",
    "plt.savefig('figure_2.3_2019_python.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2.4 Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fig4,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(10,4))\n",
    "fig = plt.figure(1)\n",
    "ax1 = fig.add_axes([.05, .05, .25, .9])\n",
    "ax2 = fig.add_axes([.40, .05, .25, .9])\n",
    "ax3 = fig.add_axes([.77, .05, .25, .9])\n",
    "#whiskers are different in python (75th percentile + wis *IQR, for example)\n",
    "# in matlab 1.5 *IQR + median\n",
    "ax1.boxplot(lev,notch=True,whis=1)\n",
    "ax1.set(xticklabels=\" \",ylabel='Level (m)')\n",
    "\n",
    "ax2.boxplot(ppt,notch=True,whis=1)\n",
    "ax2.set(xticklabels=' ',ylabel=\"Precipitation (cm)\")\n",
    "\n",
    "ax3.boxplot(temp,notch=True,whis=1)\n",
    "ax3.set(xticklabels=' ', ylabel=\"Temperature (C)\")\n",
    "\n",
    "plt.savefig('figure_2.4_2019_python.png')\n",
    "\n",
    "#Note: the length of the whiskers is computed differently in numpy boxplot than in Matlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures of central tendency\n",
    "\n",
    "We will use a mix of scipy stats and pandas routines to illustrate the basic statistical commands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one 3 column array for all 3 variables of length N years\n",
    "array = np.ones((N,3),dtype=np.float_)\n",
    "array[:,0] = lev\n",
    "array[:,1] = ppt\n",
    "array[:,2] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pandas DataFrame\n",
    "Documentation on pandas:\n",
    "http://pandas.pydata.org/pandas-docs/stable/\n",
    "\n",
    "How to load indices and data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(array, index=year.astype(str),columns=['Great Salt Lake Level','Utah Precipitation','Utah Temperature'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pthyon notebooks display frames as html tables\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some basic info + output precentiles\n",
    "basic_vals = df.describe(percentiles=[.01,.10,.25,.33,.50,.66,.75,.90,.99])\n",
    "print(basic_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pandas descriptive statistics\n",
    "https://pandas.pydata.org/pandas-docs/stable/basics.html#descriptive-statistics\n",
    "\n",
    "#useful panda info\n",
    "https://jeffdelaney.me/blog/useful-snippets-in-pandas/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In what year did the min values happen?\n",
    "df.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In what year did the max values happen?\n",
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = stats.mode(array,axis=0)\n",
    "print(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute mean of the values between the 10th and 90th percentile in the sample\n",
    "xbar_trim = stats.trim_mean(array,0.1)\n",
    "print('Trimmed mean',xbar_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute interquartile ranges\n",
    "iqr_var=stats.iqr(array,axis=0)\n",
    "print('IQR',iqr_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median absolute deviation\n",
    "df.mad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrating robust and reliant central tendency metrics\n",
    "%put in a bad value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put in one bad value\n",
    "array_wbad = np.ones((N,3),dtype=np.float_)\n",
    "array_wbad[:,0] = lev\n",
    "array_wbad[:,1] = ppt\n",
    "array_wbad[:,2] = temp\n",
    "\n",
    "array_wbad[1,:] = -9999\n",
    "xbar_wbad = np.mean(array_wbad,axis=0);\n",
    "xmed_wbad = np.median(array_wbad,axis=0);\n",
    "xbar_trim_wbad = stats.trim_mean(array_wbad,0.1);\n",
    "print('mean',xbar_wbad)\n",
    "print('median',xmed_wbad)\n",
    "print('trimmed_mean',xbar_trim_wbad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbiased estimate of pop standard deviation and variance\n",
    "std0 = np.std(array,ddof=1,axis=0)\n",
    "var0 = np.var(array,ddof=1,axis=0)\n",
    "# sample standard deviation and variance\n",
    "std1 = np.std(array,axis=0)\n",
    "var1 = np.var(array,axis=0)\n",
    "print('pop standard deviation and variance',std0,var0)\n",
    "print('sample standard deviation and variance',std1,var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness\n",
    "skew = stats.skew(array,axis=0)\n",
    "print('skewness',skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample means\n",
    "xbar= np.mean(array,axis=0)\n",
    "array_a = array - xbar;\n",
    "print(array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3) = plt.subplots(3,1,figsize=(10,5))\n",
    "ax1.bar(year,array_a[:,0],color='green')\n",
    "ax1.set(xlim=(1895,2018),ylim=(-4,4))\n",
    "ax1.set(xlabel=\"Year\",ylabel='Level (m)')\n",
    "ax1.set(xticks=decade_ticks)\n",
    "ax1.set(title=\"Figure 2.5\")\n",
    "ax2.bar(year,array_a[:,1],color='cyan')\n",
    "ax2.set(xlim=(1895,2018),ylim=(-20,20))\n",
    "ax2.set(xlabel=\"Year\",ylabel='Precipitation (cm)')\n",
    "ax2.set(xticks=decade_ticks)\n",
    "ax3.bar(year,array_a[:,2],color='red')\n",
    "ax3.set(xlim=(1895,2018),ylim=(-2,2))\n",
    "ax3.set(xlabel=\"Year\",ylabel='Temperature (C)')\n",
    "ax3.set(xticks=decade_ticks)\n",
    "\n",
    "ax1.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "ax2.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "ax3.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "\n",
    "plt.savefig('figure_2.5_2019_python.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1981-2010 climate normal\n",
    "define climate normal for 1981-2010 period. find those years\n",
    "cyr_beg = find(year == 1981);\n",
    "cyr_end = find(year == 2010);\n",
    "\n",
    "cnorm = mean(array(cyr_beg:cyr_end,:));\n",
    "cnorm_array = ones(ny,1)*cnorm;\n",
    "array_cna = array - cnorm;\n",
    "\n",
    "figure(7);\n",
    "for i=1:3\n",
    "subplot(3,1,i);\n",
    "bar(year,array_cna(:,i), colors(i));\n",
    "axis([axis_val(i,:)])\n",
    "set(gca,'XTick',decade_ticks);\n",
    "set(gca,'XTickLabel',decade_labels);\n",
    "grid on\n",
    "xlabel(xlabels(i));\n",
    "ylabel(ylabels(i));\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define climate normal for 1981-2010 period. find the range of values during those years\n",
    "#pandas handles these by index values\n",
    "clim_period=df.loc['1981':'2010']\n",
    "#print(clim_period)\n",
    "cnorm = np.mean(clim_period)\n",
    "print(cnorm)\n",
    "df_cna = df - cnorm;\n",
    "print(df_cna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,(ax1,ax2,ax3) = plt.subplots(3,1,figsize=(10,5))\n",
    "ax1.bar(year,df_cna['Great Salt Lake Level'],color='green')\n",
    "ax1.set(xlim=(1895,2018),ylim=(-4,4))\n",
    "ax1.set(xlabel=\"Year\",ylabel='Level (m)')\n",
    "ax1.set(xticks=decade_ticks)\n",
    "ax1.set(title=\"Figure 2.6\")\n",
    "ax2.bar(year,df_cna['Utah Precipitation'],color='cyan')\n",
    "ax2.set(xlim=(1895,2018),ylim=(-20,20))\n",
    "ax2.set(xlabel=\"Year\",ylabel='Precipitation (cm)')\n",
    "ax2.set(xticks=decade_ticks)\n",
    "ax3.bar(year,df_cna['Utah Temperature'],color='red')\n",
    "ax3.set(xlim=(1895,2018),ylim=(-2,2))\n",
    "ax3.set(xlabel=\"Year\",ylabel='Temperature (C)')\n",
    "ax3.set(xticks=decade_ticks)\n",
    "\n",
    "ax1.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "ax2.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "ax3.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "\n",
    "plt.savefig('figure_2.6_2019_python.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Monthly Great Salt Lake Level\n",
    "\n",
    "salt lake level begins in 1903 through 2018\n",
    "create 2d array levm for processing\n",
    "rows are years and columns are months\n",
    "dates will be the midpoint of the month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the Monthly lake level data\n",
    "yearm = np.genfromtxt('../data/gsl_monthly.csv', delimiter=',', usecols=0)\n",
    "nym = int(max(yearm) - min(yearm))+1\n",
    "print(np.size(yearm))\n",
    "monm = np.genfromtxt('../data/gsl_monthly.csv', delimiter=',', usecols=1)\n",
    "#convert lake level to meters\n",
    "levmon = .3048 * np.genfromtxt('../data/gsl_monthly.csv', delimiter=',', usecols=2)\n",
    "#get midpoint of each month as the date\n",
    "datemon =  yearm+(monm-0.5)/12.;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert from vector to 2D array with rows years and columns months\n",
    "levm = levmon.reshape((nym,12))\n",
    "datem = datemon.reshape((nym,12))\n",
    "#print(levm)\n",
    "#print(datem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compute monthly mean and sample standard deviation for each month over all years\n",
    "\n",
    "mean_m = np.mean(levm,axis=0);\n",
    "sx_m = np.std(levm,axis=0);\n",
    "print(mean_m)\n",
    "print(sx_m)\n",
    "\n",
    "#plot monthly mean;\n",
    "xb = np.arange(0.5,12.5,1)\n",
    "fig8,ax8 = plt.subplots(1,1,figsize=(7,5))\n",
    "ax8.bar(xb,mean_m,color='g',align='center',width=0.5)\n",
    "ax8.set(xlabel=\"Time of Year\",ylabel='Level(m)')\n",
    "ax8.set(xlim=(0,12.5),ylim=(1279.5,1280.1)) \n",
    "ax8.set(xticks=xb,xticklabels=['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'])\n",
    "ax8.ticklabel_format(axis='y',style='plain',useOffset=False)\n",
    "ax8.set(title=\"Figure 2.8\")\n",
    "plt.savefig('figure_2.8_2019.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute anomalies from monthly means\n",
    "levm_a = levm - mean_m;\n",
    "nom = np.size(levm_a)\n",
    "levma = levm_a.reshape(nom)\n",
    "#compute standardized anomalies\n",
    "z = levm_a/sx_m;\n",
    "za = z.reshape(nom)\n",
    "#print(levma)\n",
    "#print(za)\n",
    "#print(np.shape(za))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig7,(ax1,ax2,ax3) = plt.subplots(3,1,figsize=(10,10))\n",
    "decade_ticks = np.arange(1910,2020,10)\n",
    "ax1.bar(datemon,levmon,color='green')\n",
    "ax1.set(xlim=(1903,2019),ylim=(1277,1284))\n",
    "ax1.set(xlabel=\"Year\",ylabel='Level (m)')\n",
    "ax1.set(xticks=decade_ticks)\n",
    "ax1.set(title=\"Figure 2.7\")\n",
    "ax2.bar(datemon,levma,color='green')\n",
    "ax2.set(xlim=(1903,2019),ylim=(-2.5,4))\n",
    "ax2.set(xlabel=\"Year\",ylabel='Anomalies (m)')\n",
    "ax2.set(xticks=decade_ticks)\n",
    "ax3.bar(datemon,za,color='cyan')\n",
    "ax3.set(xlim=(1903,2018),ylim=(-2.5,4))\n",
    "ax3.set(xlabel=\"Year\",ylabel='Standardized Anomlies')\n",
    "ax3.set(xticks=decade_ticks)\n",
    "\n",
    "ax1.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "ax2.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "ax3.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "\n",
    "plt.savefig('figure_2.7_2019.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CDF of monthly lake level\n",
    "fig9,ax = plt.subplots(1,1,figsize=(10,5))\n",
    "print(nom)\n",
    "print(za)\n",
    "n, bins, patches = ax.hist(za, nom, density='True', histtype='step',\n",
    "                           cumulative=True, label='Empirical')\n",
    "ax.set(xlabel=\"Standardized Anomalies\",ylabel='Cumulative Emprical Probability')\n",
    "ax.set(xlim=(-2,max(za)))\n",
    "\n",
    "\n",
    "plt.savefig('figure_2.9_2019.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and Median smoothers\n",
    "One way is to use pandas built in functions to handle. \n",
    "These are the sorts of things pandas is intended to handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first get anomalies for Utah Precipitation only just for convenience as a Series\n",
    "ppt_vals= df['Utah Precipitation']\n",
    "ppt_climo = np.mean(ppt_vals)\n",
    "ppt_a = ppt_vals - ppt_climo\n",
    "#window is how many values to roll over and compute mean or median\n",
    "window = 3\n",
    "#iter is number of iterations to repeat\n",
    "iter = 5\n",
    "#do the first ones\n",
    "vals_mean=ppt_a.rolling(window,center=True).mean()\n",
    "vals_median=ppt_a.rolling(window,center=True).median()\n",
    "for ival in range(0,iter-1):\n",
    "    #reset the first and last values to the original data\n",
    "    vals_mean[[0]]=ppt_a.iloc[[0]]\n",
    "    vals_mean[[-1]]=ppt_a.iloc[[-1]]\n",
    "    vals_median[[0]]=ppt_a.iloc[[0]]\n",
    "    vals_median[[-1]]=ppt_a.iloc[[-1]]\n",
    "    vals_mean=vals_mean.rolling(window,center=True).mean()\n",
    "    vals_median=vals_median.rolling(window,center=True).median()\n",
    "# replace first and last values for final pass\n",
    "vals_mean[[0]]=ppt_a.iloc[[0]]\n",
    "vals_mean[[-1]]=ppt_a.iloc[[-1]]\n",
    "vals_median[[0]]=ppt_a.iloc[[0]]\n",
    "vals_median[[-1]]=ppt_a.iloc[[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Utah precipitation with mean and medians superimposed\n",
    "decade_ticks = np.arange(1900,2020,10)\n",
    "fig10,ax = plt.subplots(1,1,figsize=(10,5))\n",
    "ax.bar(year,array_a[:,1],color='cyan')\n",
    "ax.plot(year,vals_mean.values,color='green',linewidth=2);\n",
    "ax.plot(year,vals_median.values,color='red',linewidth=2);\n",
    "ax.set(xlim=(1895,2018),ylim=(-20,20))\n",
    "ax.set(xlabel=\"Year\",ylabel='Precipitation Anomalies (cm)')\n",
    "ax.set(xticks=decade_ticks)\n",
    "ax.grid(linestyle='--', color='grey', linewidth=.2)\n",
    "plt.savefig('figure_2.10_2019_python.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
